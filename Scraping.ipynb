{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1oLzlmciKnls2EqcFDzG67l2Pzp4dtsL6",
      "authorship_tag": "ABX9TyNAGlxgd+Y+gDkppgOA66h9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ApooravTyagi/Scraping-Assignment_-CoinMarketCap/blob/main/Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "\n",
        "#CSV file 1 for 50 data\n",
        "csv_file = open('coins.csv','w', newline='')\n",
        "csv_writer = csv.writer(csv_file)\n",
        "csv_writer.writerow(['name','symbol','URL'])\n",
        "\n",
        "#CSV file 2 for 1 Data\n",
        "csv_file2 = open('coins_data.csv','w', newline='')\n",
        "csv_writer2 = csv.writer(csv_file2)\n",
        "csv_writer2.writerow(['Symbol','Name','WatchlistCount','Website URL','Circulating Supply %','Price','Volume/Market Cap','Market Dominance',\n",
        "                      'Rank','Market Cap','All Time High - DATE','All Time High - PRICE','All Time Low  - DATE','All Time Low  - PRICE',\n",
        "                      'What is <Coin Name>?','Who are the founders?','What makes it unique?'\n",
        "                      ])\n",
        "\n",
        "def get_coins():\n",
        "    url = \"https://coinmarketcap.com/\"\n",
        "    source = requests.get(url).text\n",
        "    soup = BeautifulSoup(source,'lxml')\n",
        "\n",
        "    count = 0\n",
        "    cmc_links = soup.find_all('a',class_='cmc-link')\n",
        "    selected_divs = soup.find_all('div',class_='sc-16r8icm-0 dnwuAU')\n",
        "\n",
        "    #For first 10 coins\n",
        "    for div in selected_divs:\n",
        "        if(count >= 50):\n",
        "            break\n",
        "        else:\n",
        "            name = div.find('p',class_='sc-1eb5slv-0 iJjGCS').text\n",
        "            symbol = div.find('p',class_='sc-1eb5slv-0 gGIpIK coin-item-symbol').text\n",
        "            URL = \"coinmarketcap.com\" + div.find('a',class_='cmc-link')['href']\n",
        "            csv_writer.writerow([name,symbol,URL])\n",
        "            count += 1\n",
        "\n",
        "    #For remaining 40 coins\n",
        "    for link in cmc_links:\n",
        "        if(count >= 50):\n",
        "            break\n",
        "        else:\n",
        "            try:\n",
        "                name = link.find('span',class_=\"\").text\n",
        "                symbol = link.find('span',class_='crypto-symbol').text\n",
        "                URL = \"coinmarketcap.com\" + link['href']\n",
        "                csv_writer.writerow([name,symbol,URL])\n",
        "                count += 1\n",
        "            except:\n",
        "                pass\n",
        "    csv_file.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_coin_data(coin_symbol):\n",
        "    with open('coins.csv','r') as csv_file:\n",
        "        csv_reader = csv.reader(csv_file)\n",
        "        for line in csv_reader:\n",
        "            if(line[1] == coin_symbol ):\n",
        "                target_url = \"http://\" + line[2]\n",
        "                name = line[0]\n",
        "                website_url = target_url\n",
        "                break\n",
        "\n",
        "\n",
        "    url = target_url\n",
        "    source = requests.get(url).text\n",
        "    soup = BeautifulSoup(source,'lxml')\n",
        "\n",
        "    watch_list = soup.find_all('div',class_=\"namePill___3p_Ii\")[2].text.split()[1]\n",
        "    circulating_supply = soup.find('div',class_=\"supplyBlockPercentage___1g1SF\").text\n",
        "\n",
        "    table = soup.find('div',class_='sc-16r8icm-0 fIhwvd')\n",
        "    price = table.find('td').text\n",
        "\n",
        "    volume_cap = table.find_all('tr')[4].td.text\n",
        "    market_dominance = table.find_all('tr')[5].td.span.text\n",
        "    rank = table.find_all('tr')[6].td.text\n",
        "\n",
        "\n",
        "    table2 = soup.find_all('div',class_='sc-16r8icm-0 fIhwvd')[1]\n",
        "    market_cap = table2.find('td').span.text\n",
        "    over_all_div = soup.find('div',class_='sc-1lt0cju-0 srvSa').div\n",
        "\n",
        "\n",
        "\n",
        "    what_is_coin_name = []\n",
        "    who_are_the_founders = []\n",
        "    what_makes_it_unique = []\n",
        "    q1_flag = False\n",
        "    q2_flag = False\n",
        "    q3_flag = False\n",
        "\n",
        "    for tag in over_all_div:\n",
        "        if(tag.name == 'h3' ):\n",
        "            q1_flag = True\n",
        "        if(not q1_flag and tag.name == 'p'):\n",
        "            what_is_coin_name.append(tag.text)\n",
        "\n",
        "\n",
        "        if(tag.name == 'h4'):\n",
        "            q2_flag = True\n",
        "        if(not q2_flag and q1_flag and tag.name == 'p'):\n",
        "            who_are_the_founders.append(tag.text)\n",
        "\n",
        "        if(tag.name == 'h5'):\n",
        "            q3_flag = True\n",
        "        if(not q3_flag and q1_flag and q2_flag and tag.name == 'p'):\n",
        "            what_makes_it_unique.append(tag.text)\n",
        "\n",
        "\n",
        "    table3 = soup.find_all('div',class_=\"sc-16r8icm-0 fIhwvd\")[3].tbody\n",
        "    all_time_high_price = table3.find_all('tr')[4].td.span.text\n",
        "    all_time_low_price = table3.find_all('tr')[5].td.span.text\n",
        "    all_time_high_date = table3.find('small',class_='smallHeading___3DNdQ').text.split('(')[0]\n",
        "    all_time_low_date = table3.find_all('small',class_='smallHeading___3DNdQ')[1].text.split('(')[0]\n",
        "\n",
        "    #Writing the data to csv file 2\n",
        "    csv_writer2.writerow([coin_symbol,name,watch_list,website_url,circulating_supply,price,volume_cap,market_dominance,rank,market_cap,all_time_high_date,all_time_high_price,all_time_low_date,all_time_low_price,what_is_coin_name,who_are_the_founders,what_makes_it_unique])\n",
        "    csv_file2.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "Ay2Ry-Ajs2s2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_coin_data(coin_symbol):\n",
        "    with open('coins.csv','r') as csv_file:\n",
        "        csv_reader = csv.reader(csv_file)\n",
        "        for line in csv_reader:\n",
        "            if(line[1] == coin_symbol ):\n",
        "                target_url = \"http://\" + line[2]\n",
        "                name = line[0]\n",
        "                website_url = target_url\n",
        "                break\n",
        "\n",
        "    url = target_url\n",
        "    source = requests.get(url).text\n",
        "    soup = BeautifulSoup(source,'lxml')\n",
        "\n",
        "    watch_list_elem = soup.find_all('div',class_=\"namePill___3p_Ii\")\n",
        "    if len(watch_list_elem) >= 3:\n",
        "        watch_list = watch_list_elem[2].text.split()[1]\n",
        "    else:\n",
        "        watch_list = \"N/A\"\n",
        "\n",
        "    circulating_supply_elem = soup.find('div',class_=\"supplyBlockPercentage___1g1SF\")\n",
        "    circulating_supply = circulating_supply_elem.text if circulating_supply_elem else \"N/A\"\n",
        "\n",
        "    # Similarly handle other elements\n",
        "\n",
        "    csv_writer2.writerow([coin_symbol, name, watch_list, website_url, circulating_supply, ...])  # Update this line with other elements\n",
        "    csv_file2.close()\n"
      ],
      "metadata": {
        "id": "6zmp13F1tXaT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tJLxw6HLtYI5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}